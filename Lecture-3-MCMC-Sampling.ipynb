{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "##################################################\n",
    "##### Matplotlib boilerplate for consistency #####\n",
    "##################################################\n",
    "from ipywidgets import interact\n",
    "from ipywidgets import FloatSlider, IntSlider\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n",
    "\n",
    "global_fig_width = 8\n",
    "global_fig_height = global_fig_width / 1.61803399\n",
    "font_size = 12\n",
    "\n",
    "plt.rcParams['axes.axisbelow'] = True\n",
    "plt.rcParams['axes.edgecolor'] = '0.8'\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['axes.labelpad'] = 8\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "plt.rcParams['axes.titlepad'] = 16.0\n",
    "plt.rcParams['axes.titlesize'] = font_size * 1.4\n",
    "plt.rcParams['figure.figsize'] = (global_fig_width, global_fig_height)\n",
    "plt.rcParams['font.sans-serif'] = ['Computer Modern Sans Serif', 'DejaVu Sans', 'sans-serif']\n",
    "plt.rcParams['font.size'] = font_size\n",
    "plt.rcParams['grid.color'] = '0.8'\n",
    "plt.rcParams['grid.linestyle'] = 'dashed'\n",
    "plt.rcParams['grid.linewidth'] = 2\n",
    "plt.rcParams['lines.dash_capstyle'] = 'round'\n",
    "plt.rcParams['lines.dashed_pattern'] = [1, 4]\n",
    "plt.rcParams['xtick.labelsize'] = font_size\n",
    "plt.rcParams['xtick.major.pad'] = 4\n",
    "plt.rcParams['xtick.major.size'] = 0\n",
    "plt.rcParams['ytick.labelsize'] = font_size\n",
    "plt.rcParams['ytick.major.pad'] = 4\n",
    "plt.rcParams['ytick.major.size'] = 0\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generating independent samples:\n",
    "\n",
    "**Question:** how can we generate independent samples from the following (un-normalised) PDF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def P(x):\n",
    "    return 0.2*norm.pdf(x,0.4,0.2) + 0.4*norm.pdf(x,1,0.2)+ 0.3*norm.pdf(x,1.6,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def show_pdf():\n",
    "    x = np.linspace(0,2,100)\n",
    "    y = P(x)\n",
    "    plt.plot(x,y)\n",
    "    plt.fill_between(x,y,alpha=0.2)\n",
    "    plt.xlabel(r'$x$')\n",
    "    plt.ylabel(r'$P(x)$')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "show_pdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Answer:** do the following a large number of times:\n",
    "1. Generate $x$ coordinates: uniformly-distributed points from $(0, 2)$; where $2$ is the domain of the function.\n",
    "2. Generate $y$ coordinates: uniformly-distributed points from $(0, 1)$; where 1 is the maximum value of the function.\n",
    "3. If $y < P(x)$, then accept $x$ coordinate as a sample.\n",
    "4. If $y \\ge P(x)$, then reject $x$ coordinate as a sample.\n",
    "Known as **Rejection** sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "N = 100000\n",
    "x = np.random.uniform(0,2,N)\n",
    "y = np.random.uniform(0,1,N)\n",
    "x_samples = x[y < P(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(x_samples,bins=100,density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why do sampling in the first place?\n",
    "\n",
    "Samples from the posterior:\n",
    "\n",
    "$$P(\\theta | data) = \\frac{P(data|\\theta) P(\\theta)}{P(data)}$$\n",
    "\n",
    "- Shows the likely *distribution* of parameters, rather than single most likely point. Shows:\n",
    " - Correlated parameters\n",
    " - Unidentifiable parameters\n",
    " - Confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why do sampling in the first place?\n",
    "\n",
    "- Often, want to calculate the posterior mean of some parameter, $\\theta_1$:\n",
    "    \n",
    "$$\n",
    "E(\\theta_1|X) = \\int_{\\theta_1} \\int_{\\theta_{-1}} \n",
    "\\theta_1  P(\\theta_1, \\theta_{-1} | X)d \\theta_{-1} d \\theta_1\n",
    "$$\n",
    "\n",
    "where $\\theta_{-1}$ corresponds to the $d − 1$ other parameters of the\n",
    "model.\n",
    "\n",
    "- Posterior mean can be approximated by summing over posterior samples\n",
    "\n",
    "- Marginal distributions can also be obtained from posterior samples:\n",
    "\n",
    "$$\n",
    "P(\\theta_1|X) = \\int_{\\theta_{-1}} P(\\theta_1, \\theta_{-1} | X)d \\theta_{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why is generating independent samples difficult?\n",
    "\n",
    "- **Rejection sampling** requires generation of a large number\n",
    "of random points to produce relatively few samples.\n",
    "- This inefficiency increases (exponentially) with the\n",
    "dimensionality of the distribution; i.e. for posteriors with\n",
    "more parameters.\n",
    "- Other methods exist (inverse-transform sampling and\n",
    "importance sampling, for example) but they suffer from\n",
    "complexity and/or inefficiency issues.\n",
    "- We cannot calculate the denominator so are unable to use\n",
    "some of these methods.\n",
    "- Even if we had the denominator the complexity of most\n",
    "models means that independent sampling isn’t possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Is sampling finished?\n",
    "\n",
    "<center>\n",
    "<img src=\"fig/sad-clown.jpg\"> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is dependent sampling?\n",
    "\n",
    "- A sampling algorithm where the next sample depends on the current value, and the list of all (accepted) positions of the\n",
    "sampler form the sample.\n",
    "\n",
    "**Example dependent sampler:** \n",
    "\n",
    "choose a new\n",
    "position based on a local “jumping” distribution\n",
    "Suppose the next value of the sampler is drawn from a 2d\n",
    "normal distribution centred on our current position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# show dependent sampler here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dependent samplers as Markov Chains (Monte Carlo)\n",
    "\n",
    "- Where to step next is determined via a distribution\n",
    "conditional on the current parameter value.\n",
    "- This stepping is probabilistic $\\rightarrow$ *Monte Carlo*.\n",
    "- The conditional distribution only depends on the current\n",
    "value of the sampler meaning it is memoryless about past\n",
    "path.\n",
    "- This memoryless means that the path of the sampler is a\n",
    "*1st order Markov Chain*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Open questions\n",
    "\n",
    "How can we decide on the:\n",
    "1. Starting position.\n",
    "2. Jumping distribution’s shape.\n",
    "\n",
    "To ensure convergence to the posterior distribution? Especially\n",
    "because we cannot compute the posterior itself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Random Walk Metropolis\n",
    "\n",
    "A discrete example: **David Robinson’s fishing**\n",
    "    \n",
    "- David Robinson (a more fortunate cousin of Robinson\n",
    "Crusoe) is marooned on an island.\n",
    "- Access to four freshwater lakes of different sizes; each with\n",
    "a supply of fish.\n",
    "\n",
    "<center>\n",
    "<img src=\"fig/david_robinson.svg\"> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## David Robinson’s fishing\n",
    "\n",
    "- He has a terrible memory (too much coconut toddy), and\n",
    "each day forgets any estimates of lake size he made\n",
    "previously.\n",
    "- He wants to fish (at maximum) one new lake per day.\n",
    "- He possesses a coin and a solar-powered calculator that\n",
    "can generate (pseudo-)random numbers uniformly\n",
    "distributed between 0 and 1.\n",
    "- He is initially “washed up” next to lake A.\n",
    "\n",
    "<center>\n",
    "<img src=\"fig/david_robinson.svg\"> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Question:** What strategy should he use to fish as\n",
    "sustainably as possible?\n",
    "\n",
    "**Remember:** Robinson doesn’t know the # of lakes, nor\n",
    "the amount of fish in each!\n",
    "\n",
    "<center>\n",
    "<img src=\"fig/david_robinson.svg\"> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Answer:** visit each lake in proportion to the fish it contains, by\n",
    "doing the following:\n",
    "1. Each night he flips the coin.\n",
    "2. If it’s heads (tails) he proposes a move to the neighbouring\n",
    "lake in the clockwise (anticlockwise) direction.\n",
    "3. Calculates the ratio of the size of the proposed lake to the\n",
    "current one.\n",
    "4. Compares the ratio with a (pseudo-)random number from\n",
    "the calculator.\n",
    "5. If the ratio exceeds the generated number, he moves. If\n",
    "not, he stays put and fishes the same lake tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## David Robinson’s fishing: does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "x = [0, 1, 2, 3]\n",
    "lakes = [2.0, 1.0, 4.0, 2.0]\n",
    "days = np.zeros((4,N))\n",
    "current_lake = 0\n",
    "\n",
    "for i in range(1,N):\n",
    "    days[:,i] = days[:,i-1]\n",
    "    \n",
    "    # move either clockwise or counter-clockwise\n",
    "    proposed_lake = current_lake + 2*int(np.random.uniform() < 0.5) - 1\n",
    "    if proposed_lake > 3:\n",
    "        proposed_lake = 0;\n",
    "    elif proposed_lake < 0:\n",
    "        proposed_lake = 3\n",
    "        \n",
    "    # accept move based on the ratio of lake sizes\n",
    "    ratio = lakes[proposed_lake]/lakes[current_lake]\n",
    "    if ratio > np.random.uniform():\n",
    "        current_lake = proposed_lake\n",
    "        \n",
    "    days[current_lake, i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_david_robinson(i):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 8/1.618))\n",
    "    ax1.plot(x, days[:,i], 'bo', ms=8, label='poisson pmf')\n",
    "    ax1.vlines(x, 0, days[:,i], colors='b', lw=5, alpha=0.5)\n",
    "    ax2.plot(x, lakes, 'bo', ms=8, label='poisson pmf')\n",
    "    ax2.vlines(x, 0, lakes, colors='b', lw=5, alpha=0.5)\n",
    "    ax1.set_ylim(0,N/2)\n",
    "    plt.show()\n",
    "\n",
    "day_widget = IntSlider(value=5, min=0, max=N-1, step=1, continuous_update=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "interact(plot_david_robinson, i=day_widget, continuous_update=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## David Robinson’s fishing: summary\n",
    "\n",
    "- Robinson lacked knowledge of numbers of fish in each lake and the number of lakes.\n",
    "- Only knows that the number of fish in each lake is proportionate to its size.\n",
    "- His memory stops him remembering the exact sizes.\n",
    "- After about 100 days his “random” strategy is quite similar from an “omniscient” one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Defining Random Walk Metropolis\n",
    "\n",
    "Robinson’s strategy is an example of the “Random Walk Metropolis” algorithm. This has the following form:\n",
    "\n",
    "- Generate a random starting location $\\theta_0$.\n",
    "- Iterate the following for $t = 1, ..,T$:\n",
    "  - Propose a new location from a jumping distribution: \n",
    "$$\\theta_{t+1} \\sim J(\\theta_{t+1}|\\theta_t)$$.\n",
    "  - Calculate the ratio: \n",
    "$$r = \\frac{\\text{likelihood}(\\theta_{t+1}) \\times \\text{prior}(\\theta_{t+1})}{\\text{likelihood}(\\theta_t) \\times \\text{prior}(\\theta_t)}$$\n",
    "  - Compare $r$ with a uniformly-distributed number $u$ between 0 and 1.\n",
    "  - If $r \\ge u \\Rightarrow$ we move.\n",
    "  - Otherwise, we remain at our current position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "T = 2000\n",
    "chain = np.empty(T,dtype=float)\n",
    "theta0 = 1.0\n",
    "accepted = 0\n",
    "for t in range(T):\n",
    "    # Propose a new location from a jumping distribution\n",
    "    theta1 = np.random.normal(theta0,0.2)\n",
    "    \n",
    "    # Calculate the ratio\n",
    "    r = P(theta1)/P(theta0)\n",
    "    \n",
    "    # Compare r with a uniformly-distributed number between 0 and 1.\n",
    "    if r >= np.random.uniform():\n",
    "        theta0 = theta1\n",
    "    \n",
    "    # Add to chain of samples\n",
    "    chain[t] = theta0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def show_mcmc_chain(chain):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 8/1.618))\n",
    "    ax1.plot(chain)\n",
    "    ax1.set_xlabel(r'iteration $t$')\n",
    "    ax1.set_ylabel(r'parameter $\\theta$')\n",
    "    ax2.hist(chain,bins=50,density=True)\n",
    "    ax2.set_ylabel(r'probability')\n",
    "    ax2.set_xlabel(r'parameter $\\theta$')\n",
    "    ax2.set_xlim(0,2)\n",
    "    ax1.set_ylim(0,2)\n",
    "    x = np.linspace(0,2,100)\n",
    "    ax2.plot(x, P(x))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "show_mcmc_chain(chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MCMC Sampling using PINTS\n",
    "\n",
    "- We can wrap our $P(x)$ PDF using PINTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pints\n",
    "import pints.toy\n",
    "\n",
    "class MyPDF(pints.toy.ToyLogPDF): \n",
    "    \n",
    "    def __call__(self, x):\n",
    "        result = P(x)\n",
    "        if result == 0:\n",
    "            return -np.inf\n",
    "        else:\n",
    "            return np.log(result)\n",
    "    \n",
    "    def n_parameters(self):\n",
    "        return 1\n",
    "\n",
    "log_pdf = MyPDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MCMC Sampling using PINTS\n",
    "\n",
    "- and then sample using MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Create an MCMC routine\n",
    "x0 = [[1.0]]\n",
    "mcmc = pints.MCMCController(log_pdf, 1, x0, sigma0=0.2, method=pints.MetropolisRandomWalkMCMC)\n",
    "\n",
    "# Set maximum number of iterations\n",
    "mcmc.set_max_iterations(2000)\n",
    "\n",
    "# Run the method\n",
    "chains = mcmc.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "show_mcmc_chain(chains[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Walk Metropolis: benefits\n",
    "- Under quite general conditions the Random Walk\n",
    "Metropolis sampler converges asymptotically to the\n",
    "posterior.\n",
    "- However for a sufficiently large sample size the sampling\n",
    "distribution may be practically indistinguishable from the\n",
    "true posterior.\n",
    "- The algorithm requires us to be able to calculate the ratio:\n",
    "\n",
    "$$r = \\frac{\\text{likelihood}(\\theta_{t+1}) \\times \\text{prior}(\\theta_{t+1})}{\\text{likelihood}(\\theta_t) \\times \\text{prior}(\\theta_t)}$$\n",
    "\n",
    "- The ratio uses only the numerator of Bayes’ rule $\\Rightarrow$ we\n",
    "side-step calculating the denominator!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The importance of the accept/reject rule\n",
    "\n",
    "- **Question:** what’s the function of the accept/reject rule\n",
    "we use in the Metropolis algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- allows sampling from\n",
    "each point in exact proportion to the posterior height\n",
    "\n",
    "- Consider the ratio of the posterior density at point θt+1 to θt\n",
    "\n",
    "\\begin{align*}\n",
    "r &= \\frac{P(\\theta_{t+1}|X)}{P(\\theta_t|X)} \\\\\n",
    "  &= \\frac{\\frac{P(X|\\theta_{t+1})P(\\theta_{t+1})}{P(X)}}{\\frac{P(X|\\theta_t)P(\\theta_t)}{P(X)}} \\\\\n",
    "  &= \\frac{P(X|\\theta_{t+1})P(\\theta_{t+1})}{P(X|\\theta_t)P(\\theta_t)}\n",
    "\\end{align*}\n",
    "\n",
    "So the ratio of the numerators of Bayes’ rule is identical to the\n",
    "ratio of the actual posteriors.\n",
    "\n",
    "$\\Rightarrow$ if we use r to guide our stepping we will be sampling\n",
    "(eventually) from the posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do we choose the jumping distribution?\n",
    "\n",
    "- Sometimes called the “proposal distribution”.\n",
    "- In Random Walk Metropolis we use a symmetric\n",
    "distribution (relaxed in Metropolis-Hastings):\n",
    "\n",
    "$$=⇒ J(\\theta_a|\\theta_b) = J(\\theta_b|\\theta_a)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def show_proposal_distribution(sigma):\n",
    "    theta_a = 1\n",
    "    theta_b = theta_a+sigma\n",
    "    x = np.linspace(0,3,100)\n",
    "    plt.plot(x,norm.pdf(x,theta_a, sigma))\n",
    "    plt.plot(x,norm.pdf(x,theta_b, sigma))\n",
    "    plt.plot([theta_a,theta_b],[norm.pdf(theta_a,theta_b, sigma),norm.pdf(theta_b,theta_a, sigma)], color='k')\n",
    "    plt.plot([theta_a, theta_a],[0, norm.pdf(theta_a,theta_b, sigma)], color='k', ls='--')\n",
    "    plt.plot([theta_b, theta_b],[0, norm.pdf(theta_b,theta_a, sigma)], color='k', ls='--')\n",
    "    plt.xlabel(r'$\\theta$')\n",
    "    plt.ylabel(r'$J$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "show_proposal_distribution(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The importance of step size\n",
    "\n",
    "**Question:** how should we decide on the jumping kernel’s step\n",
    "size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "interact(show_proposal_distribution, sigma=FloatSlider(value=1.0, min=0, max=2.0, step=0.01), continuous_update=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def vary_step_size(log_sigma0, n):\n",
    "    x0 = [[1.0]]\n",
    "    mcmc = pints.MCMCController(log_pdf, 1, x0, sigma0=np.exp(log_sigma0), method=pints.MetropolisRandomWalkMCMC)\n",
    "    mcmc.set_max_iterations(n)\n",
    "    mcmc.set_log_to_screen(False)\n",
    "    chains = mcmc.run();\n",
    "    show_mcmc_chain(chains[0])\n",
    "    \n",
    "interact(vary_step_size, log_sigma0=FloatSlider(value=-1, min=-8, max=4, step=1,continuous_update=False), n=IntSlider(value=50, min=50, max=10000, step=1,continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step size: summary\n",
    "- Whilst step size does not affect asymptotic convergence, it does affect finite sample performance.\n",
    "- If step size is too small we do not find the typical set (area of high probability mass).\n",
    "- If step size is too large we find the typical set, but do not explore it efficiently.\n",
    "- Therefore do an initial run of sampler to find optimal step size before starting proper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Judging convergence of chains to posterior\n",
    "\n",
    "- What do we mean by convergence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def show_convergence(n):\n",
    "    x0 = [[1.0]]\n",
    "    mcmc = pints.MCMCController(log_pdf, 1, x0, sigma0=0.2, method=pints.MetropolisRandomWalkMCMC)\n",
    "    mcmc.set_max_iterations(n)\n",
    "    mcmc.set_log_to_screen(False)\n",
    "    chains = mcmc.run();\n",
    "    show_mcmc_chain(chains[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "interact(show_convergence, n=IntSlider(value=50, min=50, max=20000, step=1,continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why do we need to monitor convergence?\n",
    "- Start with an initial proposal distribution based on the jumping distribution $J$\n",
    "\n",
    "$$\\pi(\\theta) \\ne P(\\theta|X)$$.\n",
    "\n",
    "- Repeatedly take steps and use the Metropolis accept/reject rule: $\\Rightarrow \\pi(\\theta_t)$; the sampling distribution at time $t$.\n",
    "- Under a set of quite general assumptions we are guaranteed that asymptotically: \n",
    "\n",
    "$$\\pi(\\theta_t) \\rightarrow P(\\theta|X)$$.\n",
    "\n",
    "- However, when practically can we assume: $\\pi(\\theta_t) \\approx P(\\theta|X)$?\n",
    "- To monitor convergence to the posterior $\\Rightarrow$ need the posterior.\n",
    "- But we don’t have the posterior $\\Leftarrow$ the reason we are doing the sampling in the first place!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Two strategies for monitoring convergence\n",
    "\n",
    "**Strategy 1:** measure distributional separation. For example Kullback-Leibler:\n",
    "$$KL = \\int P(\\theta|X) \\log \\left( \\frac{P(θ|X)}{\\pi(\\theta_t)} \\right) d\\theta$$.\n",
    "- Motivated by information theory.\n",
    "- Can use un-normalised posterior to do this.\n",
    "- Again integral is too difficult to do.\n",
    "\n",
    "**Strategy 2:** monitor the approach to a stationary distribution.\n",
    "- We know asymptotically this will happen.\n",
    "- By design of Metropolis stepping and accept/reject rules, we know the stationary distribution is the posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Monitoring convergence of a single chain\n",
    "Initial idea:\n",
    "- Compare summaries (mean, variance, etc.) of sampling distribution for a chain at time $t$ with itself at time $t + T$.\n",
    "- If their rate of change is below a threshold $\\Rightarrow$ convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### **Question:** What is the problem with this idea?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convergence monitoring: Bob’s bees\n",
    "\n",
    "Thought experiment:\n",
    "- Imagine a house of unknown shape.\n",
    "- We have an unlimited supply of bees, each equipped with a GPS tracker allowing us to accurately monitor their position.\n",
    "\n",
    "**Question:** How can we use these to estimate the shape of the house?\n",
    "\n",
    "<center>\n",
    "<img src=\"fig/bee.svg\", height=\"200\" width=\"200\"> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convergence monitoring: Bob’s bees\n",
    "\n",
    "**Answer:**\n",
    "- Release one (at a random location in the house) and monitor its path over time.\n",
    "- Stop/collect bee after summary measures of its path stop changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "class BobsHousePDF(pints.toy.ToyLogPDF): \n",
    "    def __call__(self, x):\n",
    "        result = multivariate_normal.pdf(x,[0.25,0.25], 0.01) \\\n",
    "               + multivariate_normal.pdf(x,[0.75,0.25], 0.01) \\\n",
    "               + multivariate_normal.pdf(x,[0.75,0.75], 0.01)\n",
    "        if result > 1.35:\n",
    "            return 0\n",
    "        else:\n",
    "            return -np.inf\n",
    "    \n",
    "    def n_parameters(self):\n",
    "        return 2\n",
    "\n",
    "def bobs_bees(n):\n",
    "    pdf = BobsHousePDF()\n",
    "    x0 = []\n",
    "    for i in range(n):\n",
    "        accept = False\n",
    "        while not accept:\n",
    "            pt = [np.random.uniform(), np.random.uniform()]\n",
    "            accept = pdf(pt) == 0\n",
    "        x0.append(pt)\n",
    "    sigma0 = [0.001, 0.001]\n",
    "    mcmc = pints.MCMCController(pdf, n, x0, sigma0=sigma0, method=pints.MetropolisRandomWalkMCMC)\n",
    "    mcmc.set_max_iterations(1000)\n",
    "    mcmc.set_log_to_screen(False)\n",
    "    chains = mcmc.run();\n",
    "    \n",
    "    for chain in chains:\n",
    "        plt.plot(chain[:,0],chain[:,1])\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "bobs_bees(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### **Question:** what’s the actual shape of the house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x, y = np.mgrid[0:1:.01, 0:1:.01]\n",
    "result = np.empty(x.shape)\n",
    "pdf =  BobsHousePDF()\n",
    "for i in range(x.shape[0]):\n",
    "    for j in range(x.shape[1]):\n",
    "        result[i,j] = pdf([x[i,j],y[i,j]])\n",
    "\n",
    "plt.contourf(x, y, result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single chain problems: summary\n",
    "- One way to monitor convergence is to look for convergence in a single chain’s summary statistics.\n",
    "- This method is very susceptible to the curse of hindsight problem (“Now we’ve definitely converged on the posterior. We hadn’t a minute ago.”)\n",
    "- Particularly because chains often get stuck in subregions of $\\theta$ space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The solutions: lots of bees\n",
    "\n",
    "- Release lots of bees starting at dispersed locations in parameter space.\n",
    "- Stop recording when an individual bee’s path is indistinguishable from all others’.\n",
    "\n",
    "\n",
    "<img src=\"fig/bee.svg\" style=\"float: left; width: 15%;\">\n",
    "<img src=\"fig/bee.svg\" style=\"float: left; width: 15%;\">\n",
    "<img src=\"fig/bee.svg\" style=\"float: left; width: 15%;\">\n",
    "<img src=\"fig/bee.svg\" style=\"float: left; width: 15%;\">\n",
    "<img src=\"fig/bee.svg\" style=\"float: left; width: 15%;\">\n",
    "<p style=\"clear: both;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "bobs_bees(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple chain convergence monitoring: summary\n",
    "    \n",
    "- Start a number of chains in random dispersed locations in $\\theta$ space.\n",
    "- Chains do *not* interact with one another (in Metropolis).\n",
    "- Run each sampler until it is hard to distinguish one chain’s path from all others’.\n",
    "- Less susceptible to “curse of hindsight”, since we can see if chains aren’t mixing.\n",
    "- Not foolproof! There still may be an area of high probability mass that we miss. However, less likely to fail compared to a single chain.\n",
    "- The more chains, the better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple chain convergence monitoring: open questions\n",
    "1. How to determine “random dispersed locations” at which to start the chains?\n",
    " - Ideally use an initial proposal distribution similar to posterior shape. \n",
    " - Otherwise a good rule of thumb is “Any point you don’t mind having in a sample is a good starting point”, Charles Geyer.\n",
    "2. Which summary statistics to monitor to determine convergence? \n",
    "3. At what threshold are “between chain” statistics sufficiently similar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gelman and Rubin’s $\\hat{R}$\n",
    "\n",
    "- Gelman and Rubin (1992) had the idea of comparing within-chain to between-chain variability.\n",
    "- They quantified this comparison using:\n",
    "\n",
    "$$ \\hat{R} = \\sqrt{\\frac{W + \\frac{1}{n} (B − W)} {W}}$$,\n",
    "\n",
    "\n",
    "- where “within-chain” variability,  $W = \\frac{1}{m} \\sum_{j=1}^m s_j^2\\text{, for }m\\text{ chains}$.\n",
    "\n",
    "- and “between-chain” variability,  $B = \\frac{n}{m-1}\\sum_{j=1}^{m} \\bar{\\theta}_j - \\bar{\\theta})^2$.\n",
    "\n",
    "- When we start $B >> W$ since we start in an overdispersed position.\n",
    "- In convergence $B \\rightarrow W \\Rightarrow \\hat{R} \\rightarrow 1$ (in practice $\\hat{R} < 1.1$ usually suffices)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Warm up period\n",
    "\n",
    "- The initial proposal distribution is not the posterior.\n",
    "- We therefore discard the beginning part of the chain called the “warm up” to lessen the effect of the starting position.\n",
    "- Typically discard first half of converged chains (can also cut chains in two to monitor intra-chain convergence).\n",
    "\n",
    "<img src=\"fig/Man_Doing_Warm_Up_Exercise_Cartoon.svg\" style=\"width: 30%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Complete example: Logistic model\n",
    "\n",
    "- Lets look at a complete example of using Metropolis MCMC on a time-series model\n",
    "- We will use the Logistic equation,\n",
    "\n",
    "$$f(t) = \\frac{k}{1+(k/p_0 - 1) \\exp(-r t)}$$.\n",
    "\n",
    "- parameters are $\\boldsymbol{\\theta} = [r, k]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pints\n",
    "import pints.toy\n",
    "# Load a forward model\n",
    "model = pints.toy.LogisticModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_parameters = np.array([0.015, 500])\n",
    "times = np.linspace(0, 800, 500)\n",
    "org_values = model.simulate(real_parameters, times)\n",
    "\n",
    "# Add noise\n",
    "noise = 20\n",
    "values = org_values + np.random.normal(0, noise, org_values.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(times, values, 'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup the problem in PINTS\n",
    "\n",
    "Need to create:\n",
    "1. problem $\\Rightarrow$ likelihood\n",
    "3. prior\n",
    "4. likelihood + prior $\\Rightarrow$ posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Create an object with links to the model and time series\n",
    "problem = pints.SingleOutputProblem(model, times, values)\n",
    "\n",
    "# Create a log-likelihood function\n",
    "log_likelihood = pints.GaussianKnownSigmaLogLikelihood(problem, noise)\n",
    "\n",
    "# Create a uniform prior over the parameters\n",
    "log_prior = pints.UniformLogPrior(\n",
    "    [0.01, 400],\n",
    "    [0.02, 600]\n",
    ")\n",
    "\n",
    "# Create a posterior log-likelihood (log(likelihood * prior))\n",
    "log_posterior = pints.LogPosterior(log_likelihood, log_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup MCMC algorithm\n",
    "\n",
    "Need to choose:\n",
    "1. Number of chains\n",
    "2. Starting points\n",
    "3. Step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Choose starting points for 3 mcmc chains\n",
    "xs = [\n",
    "    real_parameters * 1.1,\n",
    "    real_parameters * 0.9,\n",
    "    real_parameters * 1.15,\n",
    "]\n",
    "\n",
    "# Choose a covariance matrix for the proposal step\n",
    "sigma0 = np.abs(real_parameters) * 5e-4\n",
    "\n",
    "# Create mcmc routine\n",
    "mcmc = pints.MCMCController(log_posterior, 3, xs, sigma0=sigma0, method=pints.MetropolisRandomWalkMCMC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sample from posterior using MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add stopping criterion\n",
    "mcmc.set_max_iterations(30000)\n",
    "\n",
    "# Disable logging mode\n",
    "mcmc.set_log_to_screen(False)\n",
    "\n",
    "# Run!\n",
    "chains = mcmc.run()\n",
    "\n",
    "# Show traces and histograms\n",
    "import pints.plot\n",
    "pints.plot.trace(chains)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discard warm up and check R-hat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Discard warm up\n",
    "chains = chains[:, 10000:, :]\n",
    "pints.plot.trace(chains)\n",
    "plt.show()\n",
    "\n",
    "# Check convergence using rhat criterion\n",
    "print('R-hat:')\n",
    "print(pints.rhat_all_params(chains))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pairwise sample plots\n",
    "\n",
    "- Illustrates any correlation between parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Look at distribution in chain 0\n",
    "pints.plot.pairwise(chains[0], kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Effective sample size\n",
    "\n",
    "- Ideally we would have independent samples from the posterior.\n",
    "- Although in general independent sampling is not possible.\n",
    "- Instead we use dependent sampling, where the next sample depends on the current value.\n",
    "- Dependence $\\Rightarrow$ less information per each additional sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A definition of effective sample size\n",
    "\n",
    "“The equivalent number of samples for an independent sampler”.\n",
    "\n",
    "**Note:** the worth of an algorithm is the # effective samples per second not # samples per second!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Measuring the cost of dependent sampling\n",
    "\n",
    "- Create effective sample size (ESS) measure such that as dependence $\\uparrow$ $\\Rightarrow$ ESS $\\downarrow$\n",
    "- One way to measure dependence is by the autocorrelation of the sampler’s value.\n",
    "\n",
    "$$ESS(\\theta_i) = \\frac{mT}{1 + 2 \\sum_{\\tau=1}^{\\infty} \\rho_\\tau(\\theta_i)}$$.\n",
    "\n",
    "- Where $m$ is the number of chains, and $T$ is the number of samples per chain, and $\\rho_\\tau$ is the $\\tau$th order autocorrelation for $\\theta_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pints.effective_sample_size(chains[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Covariance MCMC\n",
    "\n",
    "- Whole class of MCMC methods, with the aim to tune the step size $\\sigma_0$ so that the ideal acceptance rate is achieved (0.25)\n",
    "- For a $n$ dimensional parameter vector $\\theta$, the jumping distribution $J$ is a multivariate normal with an $n \\times n$ covariance matrix\n",
    "- Adaptive algorithm presented in [1] uses the sample covariance of the previously accepted samples to set the covariance matrix of $J(\\theta_i)$\n",
    "\n",
    "$$\\text{cov}(\\theta_0, \\theta_1, \\theta_2, ..., \\theta_i) = \\frac{1}{i} \\left ( \\sum_{j=0}^i \\theta_j \\theta_j^T - (i+1)\\bar{\\theta}_i\\bar{\\theta}_i^T \\right)$$\n",
    "\n",
    "where $\\bar{\\theta}_i = (1/(i+1)) \\sum_{j=0}^i \\theta_j$\n",
    "\n",
    "\n",
    "[1] *An adaptive Metropolis algorithm Heikki Haario, Eero Saksman, and Johanna Tamminen (2001) Bernoulli*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mcmc = pints.MCMCController(log_posterior, 3, xs, method=pints.AdaptiveCovarianceMCMC)\n",
    "mcmc.set_max_iterations(30000)\n",
    "mcmc.set_log_to_screen(False)\n",
    "chains = mcmc.run()\n",
    "pints.plot.trace(chains)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Result: significantly improved convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "chains = chains[:, 10000:, :]\n",
    "pints.plot.trace(chains)\n",
    "\n",
    "print('R-hat:')\n",
    "print(pints.rhat_all_params(chains))\n",
    "print('ESS:')\n",
    "print(pints.effective_sample_size(chains[0]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## List of MCMC methods in PINTS\n",
    "\n",
    "- See <https://pints.readthedocs.io/en/latest/mcmc_samplers/index.html>\n",
    " - Adaptive Covariance MCMC\n",
    " - Differential Evolution MCMC\n",
    " - DreamMCMC\n",
    " - EmceeHammerMCMC\n",
    " - Hamiltonian MCMC\n",
    " - Metropolis-Adjusted Langevin Algorithm (MALA) MCMC\n",
    " - Metropolis Random Walk MCMC\n",
    " - Population MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "1. Sampling can be used to gain insight into a distribution.\n",
    "2. Independent sampling from posterior not generally possible $\\Rightarrow$ shift to dependent sampling.\n",
    "3. Random Walk Metropolis is a MCMC algorithm that allows dependent sampling from the posterior.\n",
    "4. The efficiency of Metropolis depends on choosing the right step size.\n",
    "5. Monitoring of sampler’s convergence to the posterior is non-trivial.\n",
    "6. The use of multiple chains makes it harder to make a mistake although not impossible.\n",
    "7. We value # effective samples per second, not # samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reading list\n",
    "\n",
    "Steady eddies:\n",
    "- Chapters 10 (sampling) and 11 (Metropolis and Gibbs) from “Bayesian data analysis”, by Gelman et al. (2014), 3rd edition.\n",
    "- Chapters 3 (sampling) and 4 (linear models) from “Statistical Rethinking” by McElreath.\n",
    "- Chapter 7 (MCMC) from “Doing Bayesian data analysis”, by Kruschke, 2nd edition.\n",
    "\n",
    "Eddie the Eagle:\n",
    "- “Monte Carlo is fundamentally unsound”, O’Hagan (1987), The Statistician.\n",
    "- “Bayesian Monte Carlo”, Rasmussen and Ghahramani (2002), Advances in neural information processing systems.\n",
    "- “Methods for approximating integrals in statistics with special emphasis on Bayesian integration problems”, Evans and Swartz (1995), Statistical Science.\n",
    "- “Probabilistic numerics and uncertainty in computations”, Hennig et al. (2015), Proceedings of the Royal Society A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
